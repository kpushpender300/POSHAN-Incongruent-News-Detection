# -*- coding: utf-8 -*-
"""POSat.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1q0dUIFv5dAjn2aVtI8rZ_AQrGwr7FB8U
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
from torch.utils.data import TensorDataset, DataLoader
from tqdm.notebook import tqdm
from sklearn.metrics import roc_auc_score

from torcheval.metrics.functional import multiclass_f1_score

import nltk
import os
import pickle

is_cuda = torch.cuda.is_available()

# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.
if is_cuda:
    device = torch.device("cuda")
    print("GPU is available")
else:
    device = torch.device("cpu")
    print("GPU not available, CPU used")

# from google.colab import drive
# drive.mount('/content/drive')

path="/content/drive/MyDrive/Project/IR"
os.chdir(path)

files=os.listdir()
files

##################################### NELA DATASET ###########################################################################


train_df=pd.read_csv('nela_preprocessed_train_posat.csv')

test_df=pd.read_csv('nela_preprocessed_test_posat.csv')

train_df.dropna(inplace=True)
test_df.dropna(inplace=True)

train_df["Content"]=train_df["Headline"]+" "+train_df["Body"]

test_df["Content"]=test_df["Headline"]+" "+test_df["Body"]

train_df.drop(columns=["Headline","Body"],inplace=True)

test_df.drop(columns=["Headline","Body"],inplace=True)


word_list=set()
for index,content in enumerate(train_df["Content"]):
    for word in content.split():
        word_list.add(word)
word_list

vocab = {w: i+2 for i, w in enumerate(word_list)}
vocab["[UNK]"]=1
vocab['']=0
print(vocab)
with open('vocab.pkl', 'wb') as f:
    pickle.dump(vocab, f)

with open('vocab.pkl', 'rb') as f:
    vocab = pickle.load(f)

tag_list=['NN', 'NNS', 'NNP', 'NNPS','VB', 'VBD', 'VBG','VBN', 'VBP', 'VBZ','JJ', 'JJR', 'JJS','WP','WRB','CD']

review_len = [i.count(" ") for i in train_df["Content"]]
pd.Series(review_len).hist()
plt.title("Word length of train content(Headline+Body)")
plt.show()
pd.Series(review_len).describe()

max_length=441

import nltk
nltk.download('punkt')

nltk.download('averaged_perceptron_tagger')

def calculate_tag(text):
    tag=[]
    word=[]
    tokens = nltk.word_tokenize(text)
    tokens=tokens[:max_length]
    tagged = nltk.pos_tag(tokens)
    for i in tagged:
        if i[1] in tag_list:
            tag.append(i[1])
            try:
                word.append(vocab[i[0]])
            except:
                word.append(vocab["[UNK]"])
    output=[word,tag]
    return output

contents=train_df["Content"].values

test_contents=test_df["Content"].values

tokenized_content=[]
tag_content=[]
for content in contents:
    token_and_tag=calculate_tag(content)
    tokenized_content.append(token_and_tag[0])
    tag_content.append(token_and_tag[1])

tokenized_test_content=[]
tokenized_test_tag=[]
for content in test_contents:
    token_and_tag=calculate_tag(content)
    tokenized_test_content.append(token_and_tag[0])
    tokenized_test_tag.append(token_and_tag[1])

padded_content=[(seq+[0]*(max_length-len(seq))) for seq in tokenized_content]
padded_tag=[(seq+['']*(max_length-len(seq))) for seq in tag_content]

padded_test_content=[(seq+[0]*(max_length-len(seq))) for seq in tokenized_test_content]
padded_test_tag=[(seq+['']*(max_length-len(seq))) for seq in tokenized_test_tag]

del contents
del tokenized_content

path_to_glove_file="D:\Semester 2\Information Retreival\Assignment_1\glove.6B.100d.txt"

# path_to_glove_file="/content/drive/MyDrive/Project/IR/glove.6B.100d.txt"

embeddings_index = {}
with open(path_to_glove_file) as f:
    for line in f:
        word, coefs = line.split(maxsplit=1)
        coefs = np.fromstring(coefs, "f", sep=" ")
        embeddings_index[word] = coefs

print("Found %s word vectors." % len(embeddings_index))

num_tokens = len(vocab) + 2
embedding_dim = 100
hits = 0
misses = 0

# Prepare embedding matrix
embedding_matrix = np.zeros((num_tokens, embedding_dim))
for word, i in vocab.items():
    embedding_vector = embeddings_index.get(word)
    if embedding_vector is not None:
        # Words not found in embedding index will be all-zeros.
        # This includes the representation for "padding" and "OOV"
        embedding_matrix[i] = embedding_vector
        hits += 1
    else:
        misses += 1
print("Converted %d words (%d misses)" % (hits, misses))

pos_vocab={}
for index,tag in enumerate(tag_list):
    pos_vocab[tag]=index+1
pos_vocab[""]=0


padded_tag=[[pos_vocab[tag] for tag in tags] for tags in padded_tag]

padded_test_tag=[[pos_vocab[tag] for tag in tags] for tags in padded_test_tag]

train_data = TensorDataset(torch.tensor(padded_content),torch.tensor(padded_tag),torch.tensor(train_df["Label"].values))

test_data = TensorDataset(torch.tensor(padded_test_content),torch.tensor(padded_test_tag),torch.tensor(test_df["Label"].values))

# dataloaders
batch_size = 128

train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)

test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)

dataiter = iter(test_loader)
sample_content,sample_tag,sample_stance=next(dataiter)
print("sample content",sample_content)
print("sample tag",sample_tag)
print("sample stance",sample_stance)

embedding_matrix=torch.from_numpy(embedding_matrix).to(device)

class POSat(nn.Module):
    def __init__(self,word_embed_dim,pos_embed_dim,lstm_hidden_dim,num_layers,batch_size):
        super(POSat,self).__init__()
        
        self.lstm_hidden_dim=lstm_hidden_dim
        self.pos_embed_dim=pos_embed_dim
        self.word_embed_dim=word_embed_dim
        self.num_layers=num_layers
        self.batch_size=batch_size
        
        # Pos embedding
        self.pos_embed=nn.Embedding(len(pos_vocab),self.pos_embed_dim,padding_idx=0)
        torch.nn.init.uniform_(self.pos_embed.weight, a=-0.1, b=0.1)
        # Glove embedding
        self.glove_embeddings=nn.Embedding.from_pretrained(embedding_matrix,freeze=True,padding_idx=0)
        #dense layer
        self.dense_layer=nn.Linear(self.pos_embed_dim,self.word_embed_dim)
        # Relu
        self.relu=nn.ReLU()
        # biLSTM
        self.biLstm=nn.LSTM(input_size=self.word_embed_dim,hidden_size=self.lstm_hidden_dim,num_layers=self.num_layers,bidirectional=True,batch_first=True)
        #self attention
        self.self_attn = nn.MultiheadAttention(2*lstm_hidden_dim, num_heads=1,batch_first=True)
        # linear before softmax
        self.linear_softmax=nn.Linear(2*lstm_hidden_dim,2)
        # #softmax
        # self.softmax=nn.Softmax(dim=1)
    def forward(self,content,tags):
        pos_tag_sequence=self.pos_embed(tags)
        sequence_tensor=self.glove_embeddings(content).to(torch.float32)
        pos_boosted_sequence_tensor=sequence_tensor*self.relu(self.dense_layer(pos_tag_sequence))
        bilstm_output,_=self.biLstm(pos_boosted_sequence_tensor)
        attn_output,_=self.self_attn(bilstm_output,bilstm_output,bilstm_output)
        document=attn_output.sum(dim=1)
        output=self.linear_softmax(document)
        # output=self.softmax(self.linear_softmax(document))
        return output



criterion = nn.CrossEntropyLoss()

def accuracy(actual,pred):
  return torch.sum(actual==pred).item()

from torcheval.metrics.aggregation.auc import AUC

model=POSat(100,6,200,1,128).to(device)
epochs=20
clip = 6
test_loss_min = np.Inf
lr= 0.003
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=lr)
train_loss_values = []
test_loss_values = []
epoch_count = []
train_accs= []
test_accs = []
for epoch in range(epochs):
    train_losses = []
    train_macro_f1 = []
    train_acc=[]
    model.train()
    for content,tags,labels in tqdm(train_loader):
        content,tags,labels=content.to(device),tags.to(device),labels.to(device)
        output = model(content,tags)
        loss=criterion(output,labels)
        train_losses.append(loss.item())
        train_pred=torch.argmax(output, dim=1)
        train_macro_f1.append(multiclass_f1_score(train_pred, labels, num_classes=2,average="macro").item())
        train_acc.append(accuracy(train_pred,labels)/len(labels))
        optimizer.zero_grad()
        loss.backward()
        nn.utils.clip_grad_norm_(model.parameters(), clip)
        optimizer.step()
    epoch_train_loss=np.mean(train_losses)
    epoch_macro_f1_train=np.mean(train_macro_f1)
    epoch_train_acc=np.mean(train_acc)
    train_loss_values.append(epoch_train_loss)
    train_accs.append(epoch_train_acc)
    model.eval()
    with torch.inference_mode():
        test_losses=[]
        test_macro_f1=[] 
        test_acc=[]
        for content,tags,labels in tqdm(test_loader):
            content,tags,labels=content.to(device),tags.to(device),labels.to(device)
            test_pred=model(content,tags)
            test_losses.append(criterion(test_pred, labels).item())
            test_pred=torch.argmax(test_pred, dim=1)
            test_macro_f1.append(multiclass_f1_score(test_pred, labels, num_classes=2,average="macro").item())
            test_acc.append(accuracy(test_pred,labels)/len(labels))
        epoch_test_loss=np.mean(test_losses)
        epoch_macro_f1_test=np.mean(test_macro_f1)
        epoch_test_acc=np.mean(test_acc)
    test_loss_values.append(epoch_test_loss)
    print("Epoch",epoch," Train loss",epoch_train_loss,"Train Acc",epoch_train_acc,"Macro F1",epoch_macro_f1_train)
    print("Epoch",epoch,"Test loss",epoch_test_loss,"Test Acc",epoch_test_acc,"Macro F1",epoch_macro_f1_test)
    if epoch_test_loss <= test_loss_min:
        torch.save(model.state_dict(), path+'/working/state_dict.pt')
        print('Test loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(test_loss_min,epoch_test_loss))
        test_loss_min = epoch_test_loss
    print(25*'==')

# Instantiate a new instance of our model (this will be instantiated with random weights)
model = POSat(100,6,200,1,128).to(device)

# Load the state_dict of our saved model (this will update the new instance of our model with trained weights)
model.load_state_dict(torch.load(f=path+'/working/state_dict.pt',map_location=torch.device('cpu')))
model.eval()


"""## Evaluate on Derived Nela Train"""

test_df_fnc=pd.read_csv('nela_train_derived_preprocessed.csv')
test_df_fnc.dropna(inplace=True)
test_df_fnc["Content"]=test_df_fnc["Headline"]+" "+test_df_fnc["Body"]
test_df_fnc.drop(columns=["Headline","Body"],inplace=True)
test_fnc_contents=test_df_fnc["Content"].values
tokenized_test_content_fnc=[]
tokenized_test_tag_fnc=[]
for content in test_fnc_contents:
    token_and_tag=calculate_tag(content)
    tokenized_test_content_fnc.append(token_and_tag[0])
    tokenized_test_tag_fnc.append(token_and_tag[1])
padded_test_content_fnc=[(seq+[0]*(max_length-len(seq))) for seq in tokenized_test_content_fnc]
padded_test_tag_fnc=[(seq+['']*(max_length-len(seq))) for seq in tokenized_test_tag_fnc]
padded_test_tag_fnc=[[pos_vocab[tag] for tag in tags] for tags in padded_test_tag_fnc]
test_data_fnc = TensorDataset(torch.tensor(padded_test_content_fnc),torch.tensor(padded_test_tag_fnc),torch.tensor(test_df_fnc["Label"].values))
test_loader_fnc = DataLoader(test_data_fnc, shuffle=True, batch_size=batch_size)
dataiter = iter(test_loader_fnc)
sample_content,sample_tag,sample_stance=next(dataiter)
print("sample content",sample_content)
print("sample tag",sample_tag)
print("sample stance",sample_stance)

test_losses=[]
test_macro_f1=[] 
test_acc=[]
for content,tags,labels in tqdm(test_loader_fnc):
  content,tags,labels=content.to(device),tags.to(device),labels.to(device)
  test_pred=model(content,tags)
  test_losses.append(criterion(test_pred, labels).item())
  test_pred=torch.argmax(test_pred, dim=1)
  test_macro_f1.append(multiclass_f1_score(test_pred, labels, num_classes=2,average="macro").item())
  test_acc.append(accuracy(test_pred,labels)/len(labels))
test_loss=np.mean(test_losses)
macro_f1_test=np.mean(test_macro_f1)
test_acc=np.mean(test_acc)
print("Loss on derived train nela",test_loss)
print("Accuracy on derived train nela",test_acc)
print("Macro F-1 on derived train nela",macro_f1_test)

"""## Evaluate on Derived Nela Test"""

test_df_fnc=pd.read_csv('nela_test_derived_preprocessed.csv')
test_df_fnc.dropna(inplace=True)
test_df_fnc["Content"]=test_df_fnc["Headline"]+" "+test_df_fnc["Body"]
test_df_fnc.drop(columns=["Headline","Body"],inplace=True)
test_fnc_contents=test_df_fnc["Content"].values
tokenized_test_content_fnc=[]
tokenized_test_tag_fnc=[]
for content in test_fnc_contents:
    token_and_tag=calculate_tag(content)
    tokenized_test_content_fnc.append(token_and_tag[0])
    tokenized_test_tag_fnc.append(token_and_tag[1])
padded_test_content_fnc=[(seq+[0]*(max_length-len(seq))) for seq in tokenized_test_content_fnc]
padded_test_tag_fnc=[(seq+['']*(max_length-len(seq))) for seq in tokenized_test_tag_fnc]
padded_test_tag_fnc=[[pos_vocab[tag] for tag in tags] for tags in padded_test_tag_fnc]
test_data_fnc = TensorDataset(torch.tensor(padded_test_content_fnc),torch.tensor(padded_test_tag_fnc),torch.tensor(test_df_fnc["Label"].values))
test_loader_fnc = DataLoader(test_data_fnc, shuffle=True, batch_size=batch_size)
dataiter = iter(test_loader_fnc)
sample_content,sample_tag,sample_stance=next(dataiter)
print("sample content",sample_content)
print("sample tag",sample_tag)
print("sample stance",sample_stance)

test_losses=[]
test_macro_f1=[] 
test_acc=[]
for content,tags,labels in tqdm(test_loader_fnc):
  content,tags,labels=content.to(device),tags.to(device),labels.to(device)
  test_pred=model(content,tags)
  test_losses.append(criterion(test_pred, labels).item())
  test_pred=torch.argmax(test_pred, dim=1)
  test_macro_f1.append(multiclass_f1_score(test_pred, labels, num_classes=2,average="macro").item())
  test_acc.append(accuracy(test_pred,labels)/len(labels))
test_loss=np.mean(test_losses)
macro_f1_test=np.mean(test_macro_f1)
test_acc=np.mean(test_acc)
print("Loss on derived test nela",test_loss)
print("Accuracy on derived test nela",test_acc)
print("Macro F-1 on derived test nela",macro_f1_test)

"""####################################################### FNC ##########################################################
Train on FNC Dataset
"""

train_df_fnc=pd.read_csv('preprocessed_fnc_train.csv')
train_df_fnc.dropna(inplace=True)
train_df_fnc["Content"]=train_df_fnc["Headline"]+" "+train_df_fnc["Body"]
train_df_fnc.drop(columns=["Headline","Body"],inplace=True)
train_fnc_contents=train_df_fnc["Content"].values

word_list_fnc=set()
for index,content in enumerate(train_fnc_contents):
    for word in content.split():
        word_list_fnc.add(word)
word_list_fnc

vocab_fnc = {w: i+2 for i, w in enumerate(word_list_fnc)}
vocab_fnc["[UNK]"]=1
vocab_fnc['']=0
print(vocab_fnc)
with open('vocab_fnc.pkl', 'wb') as f:
    pickle.dump(vocab_fnc, f)

def calculate_tag(text):
    tag=[]
    word=[]
    tokens = nltk.word_tokenize(text)
    tokens=tokens[:max_length]
    tagged = nltk.pos_tag(tokens)
    for i in tagged:
        if i[1] in tag_list:
            tag.append(i[1])
            try:
                word.append(vocab_fnc[i[0]])
            except:
                word.append(vocab_fnc["[UNK]"])
    output=[word,tag]
    return output

tokenized_train_content_fnc=[]
tokenized_train_tag_fnc=[]
for content in train_fnc_contents:
    token_and_tag=calculate_tag(content)
    tokenized_train_content_fnc.append(token_and_tag[0])
    tokenized_train_tag_fnc.append(token_and_tag[1])
padded_train_content_fnc=[(seq+[0]*(max_length-len(seq))) for seq in tokenized_train_content_fnc]

batch_size=128

padded_train_tag_fnc=[(seq+['']*(max_length-len(seq))) for seq in tokenized_train_tag_fnc]
padded_train_tag_fnc=[[pos_vocab[tag] for tag in tags] for tags in padded_train_tag_fnc]
train_data_fnc = TensorDataset(torch.tensor(padded_train_content_fnc),torch.tensor(padded_train_tag_fnc),torch.tensor(train_df_fnc["Label"].values))
train_loader_fnc = DataLoader(train_data_fnc, shuffle=True, batch_size=batch_size)
dataiter = iter(train_loader_fnc)
sample_content,sample_tag,sample_stance=next(dataiter)
print("sample content",sample_content)
print("sample tag",sample_tag)
print("sample stance",sample_stance)

test_df_fnc=pd.read_csv('preprocessed_fnc_test.csv')
test_df_fnc.dropna(inplace=True)
test_df_fnc["Content"]=test_df_fnc["Headline"]+" "+test_df_fnc["Body"]
test_df_fnc.drop(columns=["Headline","Body"],inplace=True)
test_fnc_contents=test_df_fnc["Content"].values
tokenized_test_content_fnc=[]
tokenized_test_tag_fnc=[]
for content in test_fnc_contents:
    token_and_tag=calculate_tag(content)
    tokenized_test_content_fnc.append(token_and_tag[0])
    tokenized_test_tag_fnc.append(token_and_tag[1])
padded_test_content_fnc=[(seq+[0]*(max_length-len(seq))) for seq in tokenized_test_content_fnc]
padded_test_tag_fnc=[(seq+['']*(max_length-len(seq))) for seq in tokenized_test_tag_fnc]
padded_test_tag_fnc=[[pos_vocab[tag] for tag in tags] for tags in padded_test_tag_fnc]
test_data_fnc = TensorDataset(torch.tensor(padded_test_content_fnc),torch.tensor(padded_test_tag_fnc),torch.tensor(test_df_fnc["Label"].values))
test_loader_fnc = DataLoader(test_data_fnc, shuffle=True, batch_size=batch_size)
dataiter = iter(test_loader_fnc)
sample_content,sample_tag,sample_stance=next(dataiter)
print("sample content",sample_content)
print("sample tag",sample_tag)
print("sample stance",sample_stance)

num_tokens = len(vocab_fnc) + 2
embedding_dim = 100
hits = 0
misses = 0

# Prepare embedding matrix
embedding_matrix = np.zeros((num_tokens, embedding_dim))
for word, i in vocab_fnc.items():
    embedding_vector = embeddings_index.get(word)
    if embedding_vector is not None:
        # Words not found in embedding index will be all-zeros.
        # This includes the representation for "padding" and "OOV"
        embedding_matrix[i] = embedding_vector
        hits += 1
    else:
        misses += 1
print("Converted %d words (%d misses)" % (hits, misses))

embedding_matrix=torch.from_numpy(embedding_matrix).to(device)

model=POSat(100,6,200,1,128).to(device)
epochs=12
clip = 6
test_loss_min = np.Inf
lr= 0.003
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=lr)
train_loss_values = []
test_loss_values = []
epoch_count = []
train_accs= []
test_accs = []
for epoch in range(epochs):
    train_losses = []
    train_macro_f1 = []
    train_acc=[]
    model.train()
    for content,tags,labels in tqdm(train_loader_fnc):
        content,tags,labels=content.to(device),tags.to(device),labels.to(device)
        output = model(content,tags)
        loss=criterion(output,labels)
        train_losses.append(loss.item())
        train_pred=torch.argmax(output, dim=1)
        train_macro_f1.append(multiclass_f1_score(train_pred, labels, num_classes=2,average="macro").item())
        train_acc.append(accuracy(train_pred,labels)/len(labels))
        optimizer.zero_grad()
        loss.backward()
        nn.utils.clip_grad_norm_(model.parameters(), clip)
        optimizer.step()
    epoch_train_loss=np.mean(train_losses)
    epoch_macro_f1_train=np.mean(train_macro_f1)
    epoch_train_acc=np.mean(train_acc)
    train_loss_values.append(epoch_train_loss)
    train_accs.append(epoch_train_acc)
    model.eval()
    with torch.inference_mode():
        test_losses=[]
        test_macro_f1=[] 
        test_acc=[]
        for content,tags,labels in tqdm(test_loader_fnc):
            content,tags,labels=content.to(device),tags.to(device),labels.to(device)
            test_pred=model(content,tags)
            test_losses.append(criterion(test_pred, labels).item())
            test_pred=torch.argmax(test_pred, dim=1)
            test_macro_f1.append(multiclass_f1_score(test_pred, labels, num_classes=2,average="macro").item())
            test_acc.append(accuracy(test_pred,labels)/len(labels))
        epoch_test_loss=np.mean(test_losses)
        epoch_macro_f1_test=np.mean(test_macro_f1)
        epoch_test_acc=np.mean(test_acc)
    test_loss_values.append(epoch_test_loss)
    print("Epoch",epoch," Train loss",epoch_train_loss,"Train Acc",epoch_train_acc,"Macro F1",epoch_macro_f1_train)
    print("Epoch",epoch,"Test loss",epoch_test_loss,"Test Acc",epoch_test_acc,"Macro F1",epoch_macro_f1_test)
    if epoch_test_loss <= test_loss_min:
        torch.save(model.state_dict(), path+'/working/state_dict_fnc.pt')
        print('Test loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(test_loss_min,epoch_test_loss))
        test_loss_min = epoch_test_loss
    print(25*'==')

# Instantiate a new instance of our model (this will be instantiated with random weights)
model = POSat(100,6,200,1,128).to(device)

# Load the state_dict of our saved model (this will update the new instance of our model with trained weights)
model.load_state_dict(torch.load(f=path+'/working/state_dict_fnc.pt',map_location=torch.device('cpu')))
model.eval()

"""### Ealuate on Derived FNC Test"""

test_df_fnc=pd.read_csv('fnc_test_derived_preprocessed.csv')
test_df_fnc.dropna(inplace=True)
test_df_fnc["Content"]=test_df_fnc["Headline"]+" "+test_df_fnc["Body"]
test_df_fnc.drop(columns=["Headline","Body"],inplace=True)
test_fnc_contents=test_df_fnc["Content"].values
tokenized_test_content_fnc=[]
tokenized_test_tag_fnc=[]
for content in test_fnc_contents:
    token_and_tag=calculate_tag(content)
    tokenized_test_content_fnc.append(token_and_tag[0])
    tokenized_test_tag_fnc.append(token_and_tag[1])
padded_test_content_fnc=[(seq+[0]*(max_length-len(seq))) for seq in tokenized_test_content_fnc]
padded_test_tag_fnc=[(seq+['']*(max_length-len(seq))) for seq in tokenized_test_tag_fnc]
padded_test_tag_fnc=[[pos_vocab[tag] for tag in tags] for tags in padded_test_tag_fnc]
test_data_fnc = TensorDataset(torch.tensor(padded_test_content_fnc),torch.tensor(padded_test_tag_fnc),torch.tensor(test_df_fnc["Label"].values))
test_loader_fnc = DataLoader(test_data_fnc, shuffle=True, batch_size=batch_size)
dataiter = iter(test_loader_fnc)
sample_content,sample_tag,sample_stance=next(dataiter)
print("sample content",sample_content)
print("sample tag",sample_tag)
print("sample stance",sample_stance)

test_losses=[]
test_macro_f1=[] 
test_acc=[]
for content,tags,labels in tqdm(test_loader_fnc):
  content,tags,labels=content.to(device),tags.to(device),labels.to(device)
  test_pred=model(content,tags)
  test_losses.append(criterion(test_pred, labels).item())
  test_pred=torch.argmax(test_pred, dim=1)
  test_macro_f1.append(multiclass_f1_score(test_pred, labels, num_classes=2,average="macro").item())
  test_acc.append(accuracy(test_pred,labels)/len(labels))
test_loss=np.mean(test_losses)
macro_f1_test=np.mean(test_macro_f1)
test_acc=np.mean(test_acc)
print("Loss on derived test fnc",test_loss)
print("Accuracy on derived test fnc",test_acc)
print("Macro F-1 on derived test fnc",macro_f1_test)

"""### Evaluate on Derived FNC Train"""

test_df_fnc=pd.read_csv('fnc_train_derived_preprocessed.csv')
test_df_fnc.dropna(inplace=True)
test_df_fnc["Content"]=test_df_fnc["Headline"]+" "+test_df_fnc["Body"]
test_df_fnc.drop(columns=["Headline","Body"],inplace=True)
test_fnc_contents=test_df_fnc["Content"].values
tokenized_test_content_fnc=[]
tokenized_test_tag_fnc=[]
for content in test_fnc_contents:
    token_and_tag=calculate_tag(content)
    tokenized_test_content_fnc.append(token_and_tag[0])
    tokenized_test_tag_fnc.append(token_and_tag[1])
padded_test_content_fnc=[(seq+[0]*(max_length-len(seq))) for seq in tokenized_test_content_fnc]
padded_test_tag_fnc=[(seq+['']*(max_length-len(seq))) for seq in tokenized_test_tag_fnc]
padded_test_tag_fnc=[[pos_vocab[tag] for tag in tags] for tags in padded_test_tag_fnc]
test_data_fnc = TensorDataset(torch.tensor(padded_test_content_fnc),torch.tensor(padded_test_tag_fnc),torch.tensor(test_df_fnc["Label"].values))
test_loader_fnc = DataLoader(test_data_fnc, shuffle=True, batch_size=batch_size)
dataiter = iter(test_loader_fnc)
sample_content,sample_tag,sample_stance=next(dataiter)
print("sample content",sample_content)
print("sample tag",sample_tag)
print("sample stance",sample_stance)

test_losses=[]
test_macro_f1=[] 
test_acc=[]
test_roc_auc=[]
for content,tags,labels in tqdm(test_loader_fnc):
  content,tags,labels=content.to(device),tags.to(device),labels.to(device)
  test_pred=model(content,tags)
  test_losses.append(criterion(test_pred, labels).item())
  test_pred=torch.argmax(test_pred, dim=1)
  test_macro_f1.append(multiclass_f1_score(test_pred, labels, num_classes=2,average="macro").item())
  # test_roc_auc.append(roc_auc_score(test_pred, labels))
  test_acc.append(accuracy(test_pred,labels)/len(labels))
test_loss=np.mean(test_losses)
macro_f1_test=np.mean(test_macro_f1)
test_acc=np.mean(test_acc)
# test_roc_auc=np.mean(test_roc_auc)
print("Loss on derived train fnc",test_loss)
print("Accuracy on derived train fnc",test_acc)
print("Macro F-1 on derived train fnc",macro_f1_test)
# print("ROC-AUC on derived train fnc",test_roc_auc)
